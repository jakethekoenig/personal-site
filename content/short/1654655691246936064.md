The AI risk arguments remind me of the ontological argument. 1. Imagine a maximally intelligent being 2. If your plan could stop it it wouldn't be so smart 3. Therefore your plan won't work

